%!TEX root = ../thesis.tex
% створюємо розділ
\chapter{Побудова нової моделі стохастичної контекстно-вільної граматики}
\label{chap:theory}

Метою цього розділу є побудова нової моделі стохастичної контекстно-вільної граматики, що дозволить застосовувати її для моделювання відритих текстів у криптоаналізі, також побудована модель дозволить розробку ефективніших алгоритмів навчання стохастичної контекстно-вільної граматики. Для досягнення мети розглянемо побудову моделі для стохастичних регулярних граматик, а потім перейдемо до складнішого випадку контекстно-вільних граматик.

\section{Модель стохастичних регулярних граматик}
Розглянемо побудову моделі стохастичних регуляриних граматик, що за своєю структурою є простішими ніж контекстно-вільні.
Нагадаємо, що регулярні граматики описується правилами виводу виду:
$$ A \rightarrow a B $$
$$ A \rightarrow a $$
де $A,B$ - нетермінали, $a$ - термінал.

Регулярні граматики, як відомо еквівалентні скінченим автоматам, тому можна провести деяку аналогію з прихованими моделями Маркова, ототожнивши простір прихованих станів з алфавітом нетермінальних символів, а простір спостережень з алфавітом термінальних символів, але виникає деяка проблема з описом імовірностей спостережень. Нехай деяка граматика містить правила:
$$ (p_1)\ A \rightarrow a A_1 $$
$$ (p_2)\ B \rightarrow b A_1 $$
Ми ввели префіксну нотацію для імовірностей переходів. До прикладу запис $ (0.5)\ A \rightarrow a A_1 $ означає що імовірність застосування правила $ A \rightarrow a A_1 $ дорівнює $0.5$. В класичній прихованій марківській моделі спершу визначаєть наступний латентний стан, а потім відповідно до нього визначається наступне спостереження, а у випадку регулярної граматики застосування правила передбачує одночасність переходу і спостереження. Тому в записаному вище прикладі граматики у випадку ототожнення стохастичної регулярної граматики і прихованої моделі Маркова із станів $A,\ B$ переходимо до стану $A_1$, а потім виникає проблема який із термінальних символів нам згенерувати: $a$ чи $b$. Щоб уникнути цієї проблеми введемо \textit{приховану модель Маркова другого порядку за спостереженнями}:
\begin{definition}
  \textit{Прихованою моделлю Маркова другого порядку за спостереженнями} з простором латентних(прихованих) станів $E = \{ 1,\dots,n \}$ та простором спостережень $O = \{ 1,\dots,m \}$ називається двохвимірний стохастичний процес $ \{ (X_t, Y_t),\ t \in \mathbb{N} \},\ \ X_t \in E,\ Y_t \in O $, що має властивості:
  \begin{itemize}
    \item $ \{ X_t,\ t \in \mathbb{N} \} $ - однорідний ланцюг Маркова.
    \item $ \forall t > 1 \colon P(Y_t = k | X_{1:t}) = P(Y_t = k | X_t, X_{t-1}),\ k \in O $
  \end{itemize}
\end{definition}
Зауважимо, що як тільки буде застосоване правило виду $ A \rightarrow a $, то граматичний вивід закінчується і описана вище прихована модель Маркова переходитиме до порожнього стану $\epsilon$ із завершенням своєї роботи. Замість матриці спостережень в випадку розглянутого узагальнення буде використаний тензор 3-го рангу. Позначати параметри прихованої модель Маркова другого порядку за спостереженнями будемо впорядкованою трійкою: $\lambda = \big\langle Q, T, \pi \big\rangle$, де $Q$ - матриця переходів, $T$ - тензор спостережень, $\pi$ - розподіл початкового латентного стану.
Таким чином ввівши таке узагальнення можемо сформулювати і довести наступну теорему:
\begin{theorem}
  Для кожної стохастичної регулярної граматики існує прихована модель Маркова другого порядку за спостереженнями, що допускає таку саму стохастичну мову.
\end{theorem}
\begin{proof}
Доведення будемо проводити конструктивним шляхом, показуючи для кожного етапу граматичного виводу його еквівалент в термінах прихованих моделей Маркова.
Нехай маємо стохастичну регулярну граматику $ G = \big\langle N, \Sigma, S, R, \mathbb{P}\big\rangle $. $|N| = n,\ |\Sigma| = m $.
\begin{itemize}
  \item Введемо приховану модель Маркова другого порядку за спостереженнями $ \{ (X_t, Y_t) \} $ з параметрами $\lambda = \big\langle Q, T, \pi \big\rangle$ з простором латентних станів $N \cup \{ \epsilon \}$ та простором спостережень $\Sigma$.
  \item Початковий розподіл $\pi$ задамо у вигляді: $ \pi \colon P(X_1 = S) = 1 $, тобто модель стартує з початкового нетерміналу граматики.
  \item Ініціалізуємо матрицю переходів $Q$ наступним чином:
  $$ q_{AB} = \sum_{a \in \Sigma} P(A \rightarrow a B) \ \forall A \in N,\ B \in N \cup \{ \epsilon \} $$
  \item Ініціалізуємо тензор спостережень $T$ наступним чином:
  $$ t_{ABa} = \frac{P(A \rightarrow a B)}{q_{AB}} $$
\end{itemize}
Таким чином, якщо запустити модель, вона буде в точності імітувати вивід слова в стохастичній регулярній граматиці. Термінація моделі буде здійснена при досяганні порожнього стану $\epsilon$, тобто в термінах граматики - застосування правила виду $ A \rightarrow a $.
\end{proof}
\begin{claim}
  Алгоритм перетворення стохастичної регулярної граматики до прихованої моделі Маркова другого порядку за спостереженнями має складність $\mathcal{O}(l)$, де $l$ - кількість правил виводу в граматиці.
\end{claim}
\begin{proof}
  З вигляду описаного вище нами алгоритму легко побачити, що для кожного правила граматики необхідно оновлювати тензор спостережень та матрицю переходів. Для цього необхідно $\mathcal{O}(l)$ операцій. Зауважимо що при ініціалізації матриці переходів не потрібно на кожному кроці сумувати по всім терміналам.
\end{proof}

Оскільки був доведений факт еквівалентності стохастичних регулярних граматик і прихованих моделей Маркова другого порядку за спостереженнями, можемо використати модифікований алгоритм Баума-Велша для навчання за множиною ланцюжків спостережень[15]. Варто зазначити, що факт еквівалентності був відомий і раніше, зокрема в [9] описано механізм еквівалентності, проте формально не описано умови, які накладені при цьому на приховану модель Маркова(її другий порядок).

\section{Ланцюги Маркова зі стеком}
Тепер можна узагальнити модель побудовану для стохастичних регулярних граматик на випадок стохастичних контекстно-вільних граматик. Для цього використаємо той факт, що кожна контекстно-вільна граматика може бути представлена у вигляді граматики в 2-нормальній формі Грейбах, оскільки структура її дуже подібна до регулярної граматики з єдиним обмеженням, що в правій частині правил виводу може знаходитись максимально 2 нетермінали. Така структура правил виводу наштовхує на думку, що для послідовного застосування правил виводу нам потрібно деяка пам'ять. Дійсно, в теорії граматик доведено факт, що стохастичні контекстно-вільні граматики еквівалентні недетермінованим автоматам з магазинною пам'яттю(стеком) саме через представлення граматики в нормальній формі Грейбах.

Введемо деяке узагальнення ланцюга Маркова, а саме - \textit{ланцюг Маркова зі стеком}:
\begin{definition}
  \textit{Стеком над множиною X} називається скінчена множина $S$, що складається з елементів множини $X$ з введеним на ній лінійним порядком. Максимальний елемент відносно цього порядку будемо називати вершиною стеку.
\end{definition}
Введемо деякі операції зі стеком $S$:
\begin{enumerate}
  \item \textit{S.Top} - повертає вершину стеку, якщо він не порожній, інакше порожній символ $\epsilon$.
  \item \textit{S.Push(a)} - записує в стек нову вершину $a$, якщо вона не дорівнює порожньому символу $\epsilon$.
  \item \textit{S.Pop} - вилучає стару вершину з стеку.
\end{enumerate}
\begin{definition}
  \textit{Ланцюгом Маркова зі стеком} з простором станів $E$ називається стохастичний процес $ \{ (X_t, S_t)\ t \in \mathbb{N} \}$ ($X_t \in E \cup \{ \epsilon \} $, $S_t$ - стек над множиною $E \cup \{ \epsilon \}$ в момент часу $t$), такий що переходи між станами здійснюються за алгоритмом:
  \begin{enumerate}
    \item $S_t = S_{t-1}$
    \item $ P(X_t = i,\ S_t.Push(k) | X_{1:t-1}) = P(X_t = i,\ S_t.Push(k) | X_{t-1}) $,
    $ P(X_t = i,\ S_t.Push(k) | X_{t-1}=j) = p_{jik} $
    \item Якщо після переходу $X_t = \epsilon$ та $ S_t.Top \neq \epsilon $, то новий стан $X_t$ визначається: $ X_t = S_t.Top,\ S_t.Pop $. Якщо $X_t = \epsilon$ та $ S_t.Top = \epsilon $, то ланцюг завершується.
  \end{enumerate}
\end{definition}
Ланцюг Маркова зі стеком визначається тензором рангу 3 перехідних імовірностей $T = \{ p_{jik} \}_{i,j,k \in E \cup \{ \epsilon \} }$ та початковим розподілом $\pi \colon P(X_1 = i) = \pi_i$. Стек ініціалізується порожнім, хоча можливе узагальнення на довільний початковий стек.

Наведемо приклад ланцюга Маркова зі стеком.
\begin{example}
  $E = \{ 1, 2, 3 \}$, $\pi_1 = 1$
  $$ T[1] = \begin{pmatrix}
    0 & 0 & 0 & 0 \\
    0.2 & 0 & 0.1 & 0.1 \\
    0.1 & 0.2 & 0.1 & 0.1 \\
    0.1 & 0 & 0 & 0
  \end{pmatrix},
  T[2] = \begin{pmatrix}
    0.2 & 0 & 0 & 0 \\
    0 & 0 & 0.1 & 0.1 \\
    0.1 & 0.1 & 0.2 & 0.1 \\
    0.1 & 0 & 0 & 0
  \end{pmatrix}
  $$
  $$
  T[3] = \begin{pmatrix}
    0.1 & 0 & 0 & 0 \\
    0 & 0 & 0.2 & 0.1 \\
    0.1 & 0.1 & 0 & 0.1 \\
    0.1 & 0 & 0 & 0.2
  \end{pmatrix}$$
  Приклад згенерованого ланцюга:
  $ (1, \emptyset), (2, \{ 1 \}), (1, \emptyset), (3, \emptyset), (\epsilon, \emptyset) $
\end{example}
Концепція ланцюга Маркова зі стеком є фундаментом для побудови нової моделі стохастичної контекстно-вільної граматики. Дійсно, робота ланцюга дуже схожа на нетермінальну частину граматичного виводу в граматиці, що знаходиться в 2-нормальній формі Грейбах.

\section{Прихована модель Маркова зі стеком}
Отже, було показано еквівалентність стохастичних регулярних граматик і прихованих моделей Маркова другого порядку за спостереженнями. Тепер можна узагальнити випадок регулярної граматики на граматики в 2-нормальній формі Грейбах. Для цього скористаємось концепцією ланцюгів Маркова з стеком та прихованими моделями Маркова другого порядку, синтезуючи їх в одне ціле.

В попередньому розділі було помічено схожість граматичного виводу в стохастичних граматиках, що знаходяться в 2-нормальній формі Грейбах і власне введених раніше ланцюгів Маркова зі стеком. Це наштовхує на думку застосувати підхід ланцюгів Маркова зі стеком до стохастичних граматик в 2-нормальній формі Грейбах. Застосовуючи концепцію прихованих моделей Маркова можна дійти висновку, що стохастичні граматики в 2-нормальній формі Грейбах еквівалентні \textit{прихованим моделям Маркова другого порядку за спостереженнями зі стеком}. Далі введемо відповідні означення та доведемо факт даної еквівалентності.

Дійсно, всі правила виводу в 2-нормальній формі Грейбах мають вигляд:
$$ A \rightarrow a $$
$$ A \rightarrow a A_1 $$
$$ A \rightarrow a A_1 A_2 $$
Застосування першого виду правил буде приводити до переходу в стан, що знаходиться на вершині стеку з подальшим виштовхуванням вершини стеку. Застосування другого виду правил буде аналогічне функціонуванню регулярної граматики(прихованої моделі Маркова другого порядку за спостереженнями), тобто відбувається перехід до наступного стану $A_1$ без дій над стеком. Застосування же третього виду правил передбачає перехід до наступного стану $A_1$ з подальшим заштовхуванням в стек стану $A_2$. Термінація моделі буде здійснена після застосування правила першого виду при порожньому стеці.
Введемо визначення вище згаданої \textit{прихованої моделі Маркова другого порядку за спостереженнями зі стеком}, що дозволить моделювати стохастичні граматики в 2-нормальній формі Грейбах.
\begin{definition}
  \textit{Прихованою моделлю Маркова другого порядку за спостереженнями зі стеком} з простором латентних(прихованих) станів $E = \{ 1,\dots,n \}$, простором спостережень $O = \{ 1,\dots,m \}$ та стеком  називається стохастичний процес $ \{ (X_t, S_t, Y_t),\ t \in \mathbb{N} \},\ \ X_t \in E,\ Y_t \in O $, $S_t$ - стек над множиною $E$, переходи в якому здійснюються за алгоритмом:
  \begin{enumerate}
    \item Ініціалізація стеку: $S_t = S_{t-1}$
    \item Перехід між латентними станами:
    \begin{multline}
      P(X_t = i,\ S_t.Push(k) | X_{1:t-1}) = P(X_t = i,\ S_t.Push(k) | X_{t-1}),\\
      P(X_t = i,\ S_t.Push(k) | X_{t-1} = j) = p_{jik}
    \end{multline}

    \item Спостереження:
    \begin{multline}
      P(Y_t = i | X_{1:t}, S_t.Top ) = P(Y_t = i | X_t, X_{t-1}, S_t.Top),\\
      P(Y_t = i | X_t = j, X_{t-1} = k, S_t.Top = l) = q_{lkji}
    \end{multline}
    \item Якщо після переходу $X_t = \epsilon$ та $ S_t.Top \neq \epsilon $, то новий стан $X_t$ визначається: $ X_t = S_t.Top,\ S_t.Pop $. Якщо $X_t = \epsilon$ та $ S_t.Top = \epsilon $, то ланцюг завершується.
  \end{enumerate}
\end{definition}
Прихована модель Маркова зі стеком визначається тензором рангу 3 перехідних імовірностей $T = \{ p_{jik} \}_{i,j,k \in E \cup \{ \epsilon \} }$, тензором рангу 4 імовірностей спостереження $Q = \{ q_{lkji} \}_{lkj \in E \cup \{ \epsilon \}, i \in O }$ та початковим розподілом $ \pi \colon P(X_1 = i) = \pi_i,\ i \in E $. Стек ініціалізується порожнім, хоча можливе узагальнення на довільний початковий стек.
Отже, сформулюємо наступну теорему:
\begin{theorem}
  Для кожної стохастичної контекстно-вільної граматики існує прихована модель Маркова другого порядку за спостереженнями зі стеком, що допускає таку саму стохастичну мову.
\end{theorem}
\begin{proof}
  Доведення так само побудуємо конструктивним шляхом, показуючи еквівалентність граматичного виводу в обох моделях. Спочатку згадаємо, що кожну контекстно-вільну граматику можна представити у вигляді граматики в 2-нормальній формі Грейбах: $ G = \big\langle N, \Sigma, S, R, \mathbb{P}\big\rangle $, $|N| = n,\ |\Sigma| = m $.
  \begin{itemize}
    \item Введемо приховану модель Маркова другого порядку за спостереженнями зі стеком $ \{ (X_t, Y_t, S_t) \} $ з параметрами $\lambda = \big\langle T, Q, \pi \big\rangle$ з простором латентних станів $N \cup \{ \epsilon \}$ та простором спостережень $\Sigma$.
    \item Початковий розподіл $\pi$ задамо у вигляді: $ \pi \colon P(X_1 = S) = 1 $, тобто модель стартує з початкового нетерміналу граматики.
    \item Ініціалізуємо тензор переходів $T$ наступним чином:
    $$ p_{ABC} = \sum_{a \in \Sigma} P(A \rightarrow a B C) \ \forall A \in N,\ B, C \in N \cup \{ \epsilon \} $$
    \item Ініціалізуємо тензор спостережень $Q$ наступним чином:
    $$ q_{CABa} = \frac{P(A \rightarrow a B C)}{p_{ABC}} $$
  \end{itemize}
  Таким чином, перехід моделі від стану $(X_t, Y_t, S_t)$ до стану $(X_{t+1}, Y_{t+1}, S_{t+1})$ буде описувати один крок граматичного виводу. Термінація моделі буде здійснена при одночасному досяганні $ X_t = \epsilon$ і $S_t = \emptyset $.
\end{proof}
\begin{claim}
  Алгоритм перетворення стохастичної граматики в 2-нормальній формі Грейбах до прихованої моделі Маркова другого порядку за спостереженнями зі стеком має складність $\mathcal{O}(l)$, де $l$ - кількість правил виводу в граматиці.
\end{claim}
\begin{proof}
  З вигляду описаного вище нами алгоритму легко побачити, що для кожного правила граматики необхідно оновлювати тензори спостережень та переходів. Для цього необхідно $ \mathcal{O}(l) $ операцій. Зауважимо що при ініціалізації тензору переходів не потрібно на кожному кроці сумувати по всім терміналам. Реалізація алгоритму наведена в \textit{додатку А}(файл hmm2s.cpp).
\end{proof}

Варто зазначити, що доведена теорема корелює з теоремою про еквівалентність автоматів з магазинною пам'яттю і контекстно-вільних граматик і є по суті її ймовірнісним аналогом, оскільки прихована модель Маркова зі стеком за структурою нагадує стохастичний автомат з магазинною пам'яттю. В ході роботи були деякі вільності в трактуванні таких термінів, як термінація прихованої моделі Маркова. Строго кажучи термінацію можна визначити як потрапляння в порожній поглинаючий стан $\epsilon$ при порожньому стеці, тобто система залишиться в ньому вічно після потрапляння: $ P(X_t = \epsilon | X_{t-1} = \epsilon, S_t.Top = \epsilon) = 1 $.

Запропонована модель стохастичної контекстно-вільної граматики є по суті новою моделлю природної мови, узгодженість якої з реальними стохастичними контекстно-вільними граматиками буде перевірено в наступному розділі.

%!!!!!!!
\chapconclude{\ref{chap:theory}}
В розділі було розроблено нову модель стохастичних контекстно-вільних граматик. Було доведено теорему про еквівалентність стохастичних регулярних граматик і прихованих моделей Маркова другого порядку та теорему про еквівалентність стохастичних контекстно-вільних граматик та прихованих моделей Маркова другого порядку зі стеком з поліноміальним алгоритмом зведення. Таким чином була запропонована нова модель природної мови на основі прихованих моделей Маркова другого порядку за спостереженнями зі стеком.
